<div align="center">
<h1 align="center">YoloX with SAHI Implementation</h1>

## :framed_picture: Some Screenshots
The screenshots below shows the original image, the inference using YoloX and the inference using YoloX with SAHI
<p float="left">
  <img src="https://github.com/Resham-Sundar/sahi/blob/main/demo/demo_data/bev-car6.jpg" width="33%" />
  <img src="https://github.com/Resham-Sundar/sahi/blob/main/demo/demo_data/output1-yolox.png" width="33%" /> 
  <img src="https://github.com/Resham-Sundar/sahi/blob/main/demo/demo_data/output1-yolox-sahi.png" width="33%" />
</p>
<p float="left">
  <img src="https://github.com/Resham-Sundar/sahi/blob/main/demo/demo_data/bev-car7.jpeg" width="33%" />
  <img src="https://github.com/Resham-Sundar/sahi/blob/main/demo/demo_data/output2-yolox.png" width="33%" /> 
  <img src="https://github.com/Resham-Sundar/sahi/blob/main/demo/demo_data/output2-yolox-sahi.png" width="33%" />
</p>

## :star: What is actually happening
SAHI is a lightweight vision library for performing large scale object detection & instance segmentation.It already comes with a code that shows the implementation of Yolov5, MMDetection and Detectron with SAHI.Here the implementation of YoloX with SAHI has been shown and can be put to use with a YoloX model trained on custom dataset as well as with the pretrained YoloX models already available.

## :dizzy: How to use?
You can find a detailed blog showing the usage of it [here]. You can also have a look at the [colab notebook](https://colab.research.google.com/drive/1NhbFATMoH_4TPyOwnq2LS7Y66cQ5r5pV#scrollTo=3aAlTl0byPbs) showing the steps that needs to be performed for inferencing with the help of SAHI.

## :heart: Reference
<ul>
  <li>https://github.com/obss/sahi
  <li>https://github.com/Megvii-BaseDetection/YOLOX
  <li>https://www.kaggle.com/dragonzhang/yolox-inference-on-kaggle-for-cots-lb-0-520
</ul>

## :hammer_and_wrench: Extras
Readme will be updated with more info...
